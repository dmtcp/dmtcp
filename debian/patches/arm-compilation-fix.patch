Description: Compilation fix for older ARM CPUs
 Older ARM CPUs don't have 'dmb' instruction for memory barriers.  The solution
 is to use gcc atomic builtin __sync_synchronize() to provide full memory
 barrier.
 .
 dmtcp (2.3.1-2) unstable; urgency=low
 .
   * Compilation fix for older ARM CPUs.
   * Upload sponsored by Yaroslav Halchenko <debian@onerussian.com>
Author: Kapil Arya <kapil@ccs.neu.edu>

--- dmtcp-2.3.1.orig/src/dmtcpplugin.cpp
+++ dmtcp-2.3.1/src/dmtcpplugin.cpp
@@ -50,13 +50,18 @@ static dmtcp_fnptr_t userHookPreCheckpoi
 static dmtcp_fnptr_t userHookPostCheckpoint = NULL;
 static dmtcp_fnptr_t userHookPostRestart = NULL;
 
+// Remove the dead code once the other part has been verified
+#if 0
 //I wish we could use pthreads for the trickery in this file, but much of our
 //code is executed before the thread we want to wake is restored.  Thus we do
 //it the bad way.
-#if defined(__i386__) || defined(__x86_64__)
+# if defined(__i386__) || defined(__x86_64__)
 static inline void memfence(){  asm volatile ("mfence" ::: "memory"); }
-#elif defined(__arm__)
+# elif defined(__arm__)
 static inline void memfence(){  asm volatile ("dmb" ::: "memory"); }
+# endif
+#else
+# define memfence() __sync_synchronize()
 #endif
 
 EXTERNC int dmtcp_is_enabled() { return 1; }
--- dmtcp-2.3.1.orig/src/membarrier.h
+++ dmtcp-2.3.1/src/membarrier.h
@@ -35,9 +35,9 @@
 #  define IMB
 # endif
 #elif defined(__arm__)
-# define RMB asm volatile (".arch armv7-a \n\t dsb ; dmb" : : : "memory")
-# define WMB asm volatile (".arch armv7-a \n\t dsb ; dmb" : : : "memory")
-# define IMB asm volatile (".arch armv7-a \n\t isb" : : : "memory")
+# define RMB __sync_synchronize()
+# define WMB __sync_synchronize()
+# define IMB __sync_synchronize()
 #else
 # error "instruction architecture not implemented"
 #endif
--- dmtcp-2.3.1.orig/src/mtcp/mtcp_restart.c
+++ dmtcp-2.3.1/src/mtcp/mtcp_restart.c
@@ -64,6 +64,8 @@ void mtcp_check_vdso(char **environ);
 #define BINARY_NAME "mtcp_restart"
 #define BINARY_NAME_M32 "mtcp_restart-32"
 
+#define memfence() __sync_synchronize()
+
 /* struct RestoreInfo to pass all parameters from one function to next.
  * This must be global (not on stack) at the time that we jump from
  * original stack to copy of restorememoryareas() on new stack.
@@ -361,14 +363,19 @@ static void restart_fast_path()
   void *stack_ptr = rinfo.restore_addr + rinfo.restore_size - MB;
 
 #ifdef __arm__
+#if 1
+  memfence();
+# else
+  // FIXME: Remove the dead code once memfence() is stable.
 /* This delay loop was required for:
  *    ARM v7 (rev 3, v71), SAMSUNG EXYNOS5 (Flattened Device Tree)
  *    gcc-4.8.1 (Ubuntu pre-release for 14.04) ; Linux 3.13.0+ #54
  */
-{int x = 10000000;
-int y = 1000000000;
-for (; x>0; x--) for (; y>0; y--);
-}
+//{int x = 10000000;
+//int y = 1000000000;
+//for (; x>0; x--) for (; y>0; y--);
+//}
+# endif
 #endif
 
 #if 0
